[{"categories":["Music Research"],"contents":"Paper presented at NeurIPS Creative AI Track 2024.\nAbstract This paper presents a study of participants interacting with and using GaMaDHaNi, a novel hierarchical generative model for Hindustani vocal contours. To explore possible use cases in human-AI interaction, we conducted a user study with three participants, each engaging with the model through three predefined interaction modes. Although this study was conducted \u0026ldquo;in the wild\u0026rdquo;‚Äî with the model unadapted for the shift from the training data to real-world interaction ‚Äî we use it as a pilot to better understand the expectations, reactions, and preferences of practicing musicians when engaging with such a model. We note their challenges as (1) the lack of restrictions in model output, and (2) the incoherence of model output. We situate these challenges in the context of Hindustani music and aim to suggest future directions for the model design to address these gaps.\nLinks  üë©üèΩ‚ÄçüíªSupplementary Videos: https://cedar-decade-974.notion.site/Example-Videos-From-User-Studies-b0a17be4f5ed4f3184cc1d110f450541?pvs=74 üìùPaper: Coming soon!  Artwork credit: craiyon.com ","permalink":"https://snnithya.github.io/portfolio/human-ai-interaction/","tags":["Indian Music","Generative Modeling","HCI"],"title":"Exploratory Study Of Human-AI Interaction For Hindustani Music"},{"categories":["Music Research"],"contents":"Paper presented at ISMIR 2024.\nAbstract Hindustani music is a performance-driven oral tradition that exhibits the rendition of rich melodic patterns. In this paper, we focus on generative modeling of singers' vocal melodies extracted from audio recordings, as the voice is musically prominent within the tradition. Prior generative work in Hindustani music models melodies as coarse discrete symbols which fails to capture the rich expressive melodic intricacies of singing. Thus, we propose to use a finely quantized pitch contour, as an intermediate representation for hierarchical audio modeling. We propose GaMaDHaNi, a modular two-level hierarchy, consisting of a generative model on pitch contours, and a pitch contour to audio synthesis model. We compare our approach to non-hierarchical audio models and hierarchical models that use a self-supervised intermediate representation, through a listening test and qualitative analysis. We also evaluate audio model\u0026rsquo;s ability to faithfully represent the pitch contour input using Pearson correlation coefficient. By using pitch contours as an intermediate representation, we show that our model may be better equipped to listen and respond to musicians in a human-AI collaborative setting by highlighting two potential interaction use cases (1) primed generation, and (2) coarse pitch conditioning.\nLinks  üìùPaper: https://arxiv.org/abs/2408.12658 üéßAudio Samples: https://snnithya.github.io/gamadhani-samples/ üë©üèΩ‚ÄçüíªDemo: https://huggingface.co/spaces/snnithya/GaMaDHaNi üíªCode: https://github.com/snnithya/GaMaDHaNi  ","permalink":"https://snnithya.github.io/portfolio/interactive-generation/","tags":["Indian Music","Generative Modeling","HCI"],"title":"Hierarchical Generative Modeling of Melodic Vocal Contours in Hindustani Classical Music"},{"categories":["Music Research"],"contents":"For my HCI course project in Fall 2022, I decided to study the role of visual aids such as piano roll and music notation in aiding the memorization and reproduction of note onset timings in a jazz improvisation with respect to a backing track. The motivation for this kind of study is two-fold. Firstly transcription and imitation are essential while learning jazz improvisation. The task we present in our study is a form of rhythmic transcription and imitation which would be very beneficial for students of jazz. Secondly, previous studies, such as Hilebrandt et. al. have shown that for temporal information (such as the position of note onsets) is better captured in the audio modality and in the case of multimodal input (audio-visual), the visual modality doesn\u0026rsquo;t seem to play an important role at all. However, my hypothesis was that in the context of music, visual inputs must have some significant role to play in memorization/understanding of temporal information given the popularity of visualizations such as score notation among western musician performers, piano rolls among digital audio workstations etc.\nFor this project, I developed an interface . Users had to listen to (and in some cases, see) the snippets of improvisation, memorize the position of the notes with respect to the bass and drums, and tap out the note positions first along with the improvisation playing in the background, then without the improvisation (i.e. only with the bass and drums). Through quantitative and qualitative analysis, I show that visualizations do indeed help with a more accurate memorization of the note onsets.\nFor more detail, please read my report . This was preliminary work and I would love to hear feedback if you have any!\n","permalink":"https://snnithya.github.io/portfolio/rhythm_visualization/","tags":["HCI","Jazz","Publication and Patent"],"title":"Tap Tap Revolution: A study of rhythm reproduction from jazz solos with visual aids"},{"categories":["Music Research"],"contents":"Update: This paper won the \u0026lsquo;best special call paper award\u0026rsquo; at ISMIR 2022.\nIn this study, we try to use audio information (pitch and voicing) along with video information (x, y coordinated of the right and left wrists of a singer) to determine the raga of 12 s clips. We were able to show that video data, if incorporated correctly, can help correct the mistakes made by a classifier using solely audio data. We show quantitative results backed by qualitative commentary.\nLinks   Paper   Supplementary Material   Video Presentation   ","permalink":"https://snnithya.github.io/portfolio/gesture_analysis/","tags":["Indian Music","Publication and Patent"],"title":"Raga classification from vocal performance using multimodal analysis"},{"categories":["Music"],"contents":"Videos from my performance at Nexgen Multiarts festival organized by Kabir Centre For Arts \u0026amp; Culture, Montreal, Canada on 21 Oct 2023.\nArtists\n Harmonium: Sri Ninad Puranik Tabla: Sri Chinmay Kulkarni Vocals: Nithya Shikarpur  Raga Gaud Sarang   Jagadhodharana | Purandaradasa Devaranama   ","permalink":"https://snnithya.github.io/portfolio/kabir-program/","tags":["Indian Music","Performance"],"title":"Music Performance in Montreal"},{"categories":["Music"],"contents":"This is an adaptation of the famous Bollywood song Piyu Bole, from the movie Parineeta with a twist. Half way through the cover, we jazzed things up a bit :) I hope you enjoy it!\nCredits:\n Singing, Animations and vocal arrangements - Nithya Shikarpur Flute fills - Pranav Shikarpur All other instruments, mixing - Shikhar Rastogi    ","permalink":"https://snnithya.github.io/portfolio/piyu_bole/","tags":["Fusion","Indian Music","Jazz","Animation","Art"],"title":"Piyu Bole - with a jazz twist"},{"categories":["Music Research"],"contents":"This work was done with Asawari Keskar and Dr. Preeti Rao at the Digital Audio Processing Lab, IIT Bombay .\nThis is a study of a special type of concert in Hindustani classical music called Jasrangi Jugalbandi. This format involves a male and a female singer singing the same keyboard notes in 2 different ragas (scales) using the concept of mode shifting or murchana.\nThis project was published in ISMIR 2021 . Links to the paper and poster .\nBackground Transposition In various forms of modal music, it is common to obtain multiple scales from the same set of notes by just changing the tonic note. This concept is called murchana in Indian classical music. Below is an example of such a type of murchana where the singer, Gayatri, sings the notes of raga Chandrakauns in the concert tonic, i.e. G# (playing in the tanpuras), followed by the same keyboard notes in raga Madhukauns by assuming the tonic to be the madhyam (fourth note), i.e. C# above the concert tonic.   The video is a snippet from a Ranjani Gayatri concert posted on YouTube available here .\nJasrangi Jugalbandi (JJ) This type of concert was first conceptualised by Pt. Jasraj in the year 2012. Since male and female vocalists usually have natural vocal ranges that differ by around 5-7 semitones, this concert allows them to sing in their comfortable tonics (Sa) using the concept of murchana with the same notes.\nHere is an example of such a concert by Dr. Ashwini Bhide Deshpande and Pt. Sanjeev Abhyankar singing ragas Abhogi and Kalavati respectively.   Our Research Motivations Through our conversations with musicians we identified the following challenges during interaction of singers in this format of concert:\n The singers have to preserve raga specific characteristics They also have to meaningfully link phrases  Hence we sought to analyse the following:\n Study the extent to which individual raga-specific characteristics are preserved in a JJ concert Study the interaction between the 2 singers in the JJ concert  Research Material Here is a video of me talking about our research paper:   ","permalink":"https://snnithya.github.io/portfolio/jj/","tags":["Indian Music","Publication and Patent"],"title":"Computational Analysis of Melodic Mode Switching"},{"categories":["Music Research"],"contents":"I came across Max/MSP/Jitter about a month ago with the course called Twisted Signals by Prof. Jesse Stiles . Inspired by the flexibility of the language, I decided to program a movement based music synthesis program. As a dancer, I wanted to explore the possibility of letting the music follow my lead instead of choreographing my steps to the music. This is a demo of the project in its very initial stages.\nHow it works  I capture movement from my camera at 500 fps. Each frame is captured as a matrix. I subtract a 30 ms delayed frame matrix from the current frame matrix in order to capture the movement on an individual. The difference of frame matrices are used to decide the midi note value and velocity. Note values increases from the left to the right of the screen and the velocity is determined by how \u0026ldquo;big\u0026rdquo; the movement is.  All sounds from this demo are produced with Spitfire Audio\u0026amp;rsquo;s plugins.\n Screenshot of max patch being used\n  Demo of Project   Possible directions to work in  Try to detect the skeleton of a person (possibly using OpenPose ) and use that data to control the music. This would make the sound more controllable. Interact with dancers of different styles and understand their perspective and thoughts. Think about how this idea can be used to visualise music or hear dance. This could help people with hearing or seeing disabilities. I want to also experiment with Indian sounds and Indian forms to see how that works.  I would love to know any thoughts or feedback on this project. Please feel free to shoot me a mail or get in touch on social media :)\n","permalink":"https://snnithya.github.io/portfolio/max_demo/","tags":["Art"],"title":"Movement Led Music Synthesis Program - Work In Progress"},{"categories":["Music"],"contents":"Videos from my performance at a house concert in Framingham, MA on 17th December, 2022.\nArtists\n Harmonium: Sri Hirak Modi Tabla: Sri Rajesh Pai Vocals: Nithya Shikarpur  Raga Bhimpalas      Raga Sohani   ","permalink":"https://snnithya.github.io/portfolio/boston-program/","tags":["Indian Music","Performance"],"title":"Music Performance in MA, USA"},{"categories":["Other Research"],"contents":"I helped make generating figures for Chapter 5 - \u0026ldquo;Hindustani Rhythm and Computational Analysis: A Musicological Perspective\u0026rdquo; of the book - \u0026ldquo;Indian Art Music: A Computational Perspective\u0026rdquo;. I helped create interactive python notebooks for each of the figures. More information available on the github repository .\n","permalink":"https://snnithya.github.io/portfolio/sparc_chapter_figs/","tags":null,"title":"Figures for chapter in SPARC monograph - Indian Art Music: A Computational Perspective"},{"categories":["Music"],"contents":"Videos from my performance at Indian Music Experience, Bangalore on 17th December, 2022.\nArtists\n Harmonium: Sri Rohit Bharadwaj Tabla: Sri Anirudh Shankar Vocals: Nithya Shikarpur  Raga Chayanat, Madhyalay and Tarana   Diwana Kiye Shyam, Dadra   ","permalink":"https://snnithya.github.io/portfolio/17_dec_ime_program/","tags":["Indian Music","Performance"],"title":"Music Program at IME, 17th December 2022"},{"categories":["Other Research"],"contents":"From July 2019 to May 2020, I worked with Dr. Abhishek Tripathi as an intern at McAfee. This was my second project there and also resulted in a patent application. This project aimed to develop a malware detection model for partially downloaded binary files.\nInspiration This work was inspired by the research paper titled \u0026amp;ldquo;Malware Images: Visualisation and Automatic Classification\u0026amp;rdquo; by L. Nataraj et. al. The work developed an image based classifier to classify 25 different families of malware.\nOur Work Our work developed on this paper and extended it to detect malware from partially downloaded binary files as well.\nThis work has resulted in me being named inventor on a pending patent application (not yet published). This website will be updated when the application gets published.\n","permalink":"https://snnithya.github.io/portfolio/malware_binary/","tags":["Publication and Patent"],"title":"Detection of Malware in Partially Downloaded Binary Files"},{"categories":["Other Research"],"contents":"From July 2019 to May 2020, I worked with Dr. Abhishek Tripathi as an intern at McAfee. This was my first project there and also contributed towards my undergraduate thesis. This project aimed to develop a malware detection system targeted for IoT devices.\nIoT devices Internet of Things (IoT) refers to smart devices that collect and share data over the internet. These devices have found a use case in almost every setting. Smart devices encompass a large spectrum of gadgets ranging from small wearable smart watches to bigger air conditioning systems. IoT devices have found their way into several fields including medicine, entertainment and governance.\nMotivation to develop malware detection for these devices:   IoT devices are becoming increasingly popular A report by Business Insider (dated 2017), states that there will be 30 billion IoT devices by the year 2020 [link] . This trend seems to only be going upwards since then.\n  Lack of security standards\nThis surge in IoT devices has developed too quickly for the security standards to be maintained. This has made these devices highly vulnerable to malware attacks.\n  Low compute resources on such devices\nMost of these devices were designed to collect and share data to a centralized server that process the data and sends back instructions. Hence due to the lesser amount of compute resources present on IoT devices, it is difficult to use traditional malware detection methods on the device itself.\n  TLS Features TLS (Transport Layer Security) is a cryptographic protocol that allows data being transmitted over the internet to be encrypted. While it is true that an the increased use of TLS over the internet, ensures greater security, it has also allowed malware to encrypt its traffic, thus making it hard to detect. Earlier methods of malware detection from network packets used features like the port numbers, IP addresses or patterns in the payload. These features cannot be used with encrypted traffic as they become unavailable with simple feature extraction.\nHence we rely on features that can be extracted from encrypted network traffic, i.e., TLS Features. Each TLS encrypted exchange of packets begins with a TLS handshake involving the exchange of a few unencrypted packets. We extract our features from this series of packets.\n Basic TLS handshake from where we extract features. [Image source link]\n  Models developed Logistic Regression A logistic regression model involves only the computation of a sigmoid function in order to give a prediction. This can easily be done on a router, with limited memory requirements. In order to ensure that the predictions can be made within a few milliseconds (to prevent the malware from getting passed on to the device from the router), we retained only the important features determined during our model training. Only these limited number of features were used for the model prediction, thus reducing the prediction time drastically.\nDeep Learning (Autoencoders) Since, in the real world, malware packets are usually an anomaly among mostly benign packets, we decided to experiment with autoencoders due to their good performance with anomaly detection.\nAlthough in actuality, malware data is much less seen than benign data, this was not the case with the dataset we had access to. Due to privacy issues, it is surprisingly more difficult to collect benign data. Hence we developed 2 autoencoders, trained on malware and benign data separately. A combination of the predictions from both models were used to determine whether a packet was malicious or not.\nThis project contributed towards my undergraduate thesis, available at this link .\n","permalink":"https://snnithya.github.io/portfolio/tls/","tags":["Publication and Patent"],"title":"Malware Detection for IoT devices"},{"categories":["Music"],"contents":"I participated in the AI Song Contest 2022 along with some friends. We explored the use of a genetic algorithm to evolve the sounds of from modular synths. More information on our work is available here !\n","permalink":"https://snnithya.github.io/portfolio/aisongcontest2022/","tags":["Generative Modeling"],"title":"The Syntonauts: AI Song Contest 2022"},{"categories":["Music"],"contents":"This was a fun cover of the song labb par aaye, from the tv series Bandish Bandits, that I did with my friend Anjali Upadhyaya. Throughout our schooling, both of us were very interested in the Indian Arts. We finally got around to making something together :) Hope you like it!\nCredits:\n Anjali Upadhyaya - Dancing, bol recitation Nithya Shikarpur - Singing, and all other song related aspects    ","permalink":"https://snnithya.github.io/portfolio/labb_par_aaye/","tags":["Indian Music"],"title":"Labb Par Aaye - Song + Dance"},{"categories":["Other Research"],"contents":"During a summer internship at Centre for infrastructure, Sustainable Transportation and Urban Planning (CiSTUP) , Indian Institute of Sciences (IISc), Bangalore from May 2019 - July 2019, I worked on the visualisation and analysis of a phenomenon called bus bunching using data collected from BMTC buses in Bangalore. I was fortunate to work with Dr. Tarun Rambha who helped me navigate through domain knowledge that I wasn\u0026rsquo;t very familiar at the time.\nBus Bunching In public transport, bus bunching refers to the situation when 2 or more buses of the same route having evenly spaced schedules end up at the same place at the same time. For this, 1 or more buses have to violate their schedule. Causes for this could include traffic congestion, extra time taken by passengers to board or deborad the bus or temporary breakdowns of buses while on route. Effects of bus bunching can get magnified very easily. For instance, when two buses get bunched, the first bus usually gets overcrowded and the second goes near-empty. This becomes a vicious cycle that cannot be broken. This ultimately leads to inconsistent waiting times, not allowing passengers to fully rely on the bus system for their transport.\n Depiction of the effects of bus bunching. Taken from this link.\n  Data BMTC Bangalore Metropolitan Transport Corporation (BMTC) is a government agency that controls public transport bus service in Bengaluru.\nTypes of Data Collected We had access to ticketing and GPS data for a year from BMTC buses of multiple routes. Due to time constraints, I focused only on the data from January 1st, 2018. In addition, I chose only one route, with the most trips on this day - route #248 (Krishna Rajendra Market to Jalahalli Cross).\nVisualisation  Picture of visualisation of data\n  I have explained the meaning of all the components represented on the visualisation.\nMarkers Each marker represents a bus and is numbered in serial order. Buses bunched are green in colour and the other ones are red in colour.\nRoute Variables  Fare - Total fare collected by all buses on the route at a given point of time. Passengers - Total number of passangers that have boarded any bus on the route at a given point of time. Bunches - Number of bunching instances. Here, bunching instance is defined as an instant when 2 buses are travelling in the same direction but are within a certain bunching radius (in this case, 100m).  Route variables\n    Time Factor Time factor is defined as the number of seconds from the live data displayed per second in the simulation. This value can range from 10 to 1000.  Time factor\n  Bus Data It has the total fare collected and total number of passengers that have boarded the bus. The colour of the row changes based on whether it is bunched or not.  Bus data\n  Space Time Plot This a graph with the time passed on the X-axis and the distance travelled by the bus on the Y-axis (Distance is positive for the UP direction and negative for the DOWN direction). Each line plotted represents a di\u001bferent bus on the route. When two lines are parallel, it can be interpreted that they are consistently travelling with an even space between each other. However, when the lines intersect, we can see that they have bunched.  Space Time Plot\n  I used MySQL, Javascript (ChartJS), HTML and Python (pandas and modin) for this project. All the code associated along with a more detailed report can be found here ","permalink":"https://snnithya.github.io/portfolio/bus_bunching/","tags":null,"title":"Bus Bunching Analysis and Visualisation"},{"categories":["Music"],"contents":"I gave vocals for the song Geidi Prima on Trey Kams' album Supermassive!\n  ","permalink":"https://snnithya.github.io/portfolio/geidi_prima/","tags":["Indian Music","Performance"],"title":"Geidi Prima"},{"categories":["Music"],"contents":"This is my arrangement of the song Phir Le Aaya Dil from the movie Barfi. This is an a capella arrangement and only involves my voice. This was sung, recorded and put together by me at home during the lockdown.\n  ","permalink":"https://snnithya.github.io/portfolio/plad/","tags":["Indian Music","Animation","Quarantine Absurdity"],"title":"Phir Le Aaya Dil (a cappella)"},{"categories":["Music"],"contents":"This is my arrangement of fly me to the moon by Frank Sinatra. I decided to make it a little Indian by adding some swaras in the second half of the song. This was sung, recorded and put together by me at home during the lockdown.\n  ","permalink":"https://snnithya.github.io/portfolio/fmttm/","tags":["Indian Music","Jazz","Fusion","Quarantine Absurdity"],"title":"Fly Me To The Moon"},{"categories":["Music"],"contents":"This was a collaboration I did with Ronita Mookerji , a Bangalore based danseuse. In this piece she depicts how the Nava Rasas (nine emotions described in the ancient dance scriptures) play a role in the deep-seated complex myriad of emotions experienced by a woman in her urban existence through the pandemic.\nThe music for this piece was sung and arranged by me.\nCredits:\n Ronita Mookerji - Concept and Performer Gaby Davies - Video Edit Nithya Shikarpur - Vocals  The dance begins at the timestamp 19:38  \n","permalink":"https://snnithya.github.io/portfolio/nari/","tags":["Indian Music","Performance"],"title":"Nari (Woman) - a collaboration with Ronita Mookerji"},{"categories":["Music"],"contents":"This is a presentation of a kajri (semi-classical song). The lyrics are:\nKehenawa mano, O radha rani (Listen to my words, O radha rani)\nNishi andhiyari kari bijuri chamake, room-jhoom barasat paani (It is the night time and dark with lightning. It is raining heavily)\nHaath jod tori binati karata hoon, na maane mori bani (With my hands together, I am pleading with you. But you are not listening to me)\nThis song can be interpreted as being sung either by Radha\u0026rsquo;s beloved, a sakhi (friend) or her mother in an attempt to pacify her anger. I was taught this composition by my guru, Dr. Ruchira Kedar.\nI was accompanied by Sri Koushik Bhat on the Tabla.\n  ","permalink":"https://snnithya.github.io/portfolio/kajri/","tags":["Indian Music","Performance"],"title":"Kajri - Kehenawa Mano O Radha Rani"},{"categories":[""],"contents":"This is a portrait I made of my neighbour\u0026rsquo;s dog - Appu. Made with Adobe Illustrator on my laptop.\n","permalink":"https://snnithya.github.io/portfolio/appu/","tags":["Art"],"title":"Appu"},{"categories":["Music"],"contents":"This is an a cappella arrangement of the title track from the film Roja. I did the arrangement, vocals and recording for this piece.\n  ","permalink":"https://snnithya.github.io/portfolio/roja/","tags":["Indian Music","Quarantine Absurdity"],"title":"Roja - Cover"},{"categories":["Music"],"contents":"Having spent more time stuck at home than was good for me, I was struck by an inspiration to write an jingle for square wheels. Apart from their obvious defects in functionality, I think they have a pretty nice aesthetic going on :) So here is an absurd short song I wrote, arranged and recorded for square wheels. I made the animations on Blender.\n  Lyrics to the song Here are some wheels, but they are square wheels, they\u0026rsquo;re wheels in the shape of a square.\nThey don\u0026rsquo;t roll, just slide pretty nice, perfect for skiing on some ice.\nYou can\u0026rsquo;t get stuck in traffic. Absolutely no need to panic.\nDon\u0026rsquo;t move, just chill and sit along.\nNo more rolling baby, just got to slide like crazy\n\u0026lsquo;cause these aren\u0026rsquo;t round wheels after all.\n","permalink":"https://snnithya.github.io/portfolio/square_wheels/","tags":["Animation","Quarantine Absurdity","Art"],"title":"Square Wheels"},{"categories":["Music"],"contents":"Here are a quick set of drawings I drew on my phone for the song \u0026lsquo;Amma nanu devarane\u0026rsquo; to put an Instagram story. This is a song about little Krishna. Caught with butter all over his mouth by his mother Yashoda, he stubbonrly swears that he didn\u0026rsquo;t steal any butter and that everyone else got together and put butter on his mouth to frame him. The visual nature of this song inspired me to draw it out a little.\n  ","permalink":"https://snnithya.github.io/portfolio/amma_naanu/","tags":["Art","Indian Music"],"title":"Amma Nanu Devarane - Devaranama"},{"categories":["Music"],"contents":"Here is our take on Waltz for Debby by Bill Evans. I had a lot of fun interpreting this very beautiful melody with Shikhar\u0026rsquo;s playing and adding a pinch of Indianness to the singing as well :)\nCredits\n Shikhar Rastogi - Keys Nithya Shikarpur - Vocals    ","permalink":"https://snnithya.github.io/portfolio/wfd/","tags":["Jazz","Indian Music","Fusion"],"title":"Waltz for Debby"},{"categories":["Music"],"contents":"This is a song by the poet Basavanna in praise of Lord Shiva. Performed at Sripada Kshetra, Bangalore, India for the occassion of Shivaratri. This song is set in raga Madhuvanti and Bhajan Theka tala.\nCredits:\n Koushik Bhat - Tabla (Percussion accompaniment) Nithya Shikarpur - Vocals    ","permalink":"https://snnithya.github.io/portfolio/ullavarushivalaya/","tags":["Indian Music","Performance"],"title":"Ullavarushivalaya - Song for shivaratri"},{"categories":["Music"],"contents":"This is a cover of the song \u0026ldquo;Mist of Capricorn\u0026rdquo; originally performed by the band Agam. This is in the style of Carnatic fusion based on the song written by Saint Thyagaraja in raga Nalinakanti.\nCredits\n Vocals : Nithya, Shruti, Gargi, Simran Keyboards : Ritvik, Aravindh Electric Guitar : Bharat, Abhik Bass Guitar : Sagar Drums : Abhyuday Octapad : Vrajesh    ","permalink":"https://snnithya.github.io/portfolio/moc/","tags":["Indian Music","Performance","Fusion"],"title":"Mist Of Capricorn (Cover)"},{"categories":["Dance"],"contents":"I am a student of Bharathanatyam (Indian classical dance form) under the guidance of Guru P. Praveen Kumar . Here are small excerpts from a Varna in raga Todi, set to Adi tala. In this peice, the nayika (heroine) is expressing her love for her nayaka (hero), lord Shiva. This item was choreographed by my Guru.\nThis is from a performance conducted as a part of the Every Friday Cultural Evening Program (EFCEP) by Indian Council of Cultural Relations (ICCR) in collaboration with the Department of Kannada and Culture, Karnataka on 21 July, 2017.\nCredits\n Nattuvangam \u0026amp; Choreography - Guru Sri P. Praveen Kumar Vocals - Vid. D. S. Srivatsa Mridangam - Vid. Lingaraj S. Violin - Vid. Mysore R. Dayakar Dance - Nithya Shikarpur    ","permalink":"https://snnithya.github.io/portfolio/dance_rupamu/","tags":["Performance"],"title":"Bharathanatyam Dance Performance"}]